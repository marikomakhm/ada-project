{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who's the biggest tax evader?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load country codes\n",
    "df_country_codes = pd.read_csv('data/countries_codes.csv', low_memory=False).set_index('COUNTRY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "## Load panama papers datasets\n",
    "pp_edges = pd.read_csv('data/panama_papers/panama_papers.edges.csv', low_memory=False)\n",
    "pp_nodes_address = pd.read_csv('data/panama_papers/panama_papers.nodes.address.csv', low_memory=False)\n",
    "pp_nodes_entity = pd.read_csv('data/panama_papers/panama_papers.nodes.entity.csv', low_memory=False)\n",
    "pp_nodes_intermediary = pd.read_csv('data/panama_papers/panama_papers.nodes.intermediary.csv', low_memory=False)\n",
    "pp_nodes_officer = pd.read_csv('data/panama_papers/panama_papers.nodes.officer.csv', low_memory=False)\n",
    "## Load UN datasets\n",
    "un_hdi_components_2014 = pd.read_csv('data/un/hdi_components.csv', low_memory=False)\n",
    "un_gdp_per_capita = pd.read_csv('data/un/gdp_per_capita.csv', low_memory=False)\n",
    "un_gdp_per_capita_ppp = pd.read_csv('data/un/gdp_per_capita_PPP.csv', low_memory=False)\n",
    "## Load world bank datasets\n",
    "wb_gini = pd.read_csv('data/world_bank/gini_index.csv', low_memory=False)\n",
    "wb_income_share_20_per = pd.read_csv('data/world_bank/income_share_20_per.csv', low_memory=False)\n",
    "wb_population_total = pd.read_csv('data/world_bank/population_total.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIM\n",
    "wb_co2 = pd.read_excel('data/co2_emissions.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only consider statistics that date from 2000 onwards\n",
    "years_to_drop = list(map(str, np.arange(1960, 2000)))\n",
    "wb_gini = wb_gini.drop(columns=years_to_drop)\n",
    "wb_income_share_20_per = wb_income_share_20_per.drop(columns=years_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the rightmost value (most recent) for each row\n",
    "gini_values = wb_gini.stack().groupby(level=0).last().reindex(wb_gini.index)\n",
    "\n",
    "# Only select valid values and label other values as NaN\n",
    "wb_gini['Gini'] = pd.to_numeric(gini_values, errors='coerce')\n",
    "\n",
    "# Only select relevant columns\n",
    "wb_gini = wb_gini[['Country Name', 'Country Code', 'Gini']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the rightmost value (most recent) for each row\n",
    "income_share_20_per_values = wb_income_share_20_per.stack().groupby(level=0).last().reindex(wb_income_share_20_per.index)\n",
    "\n",
    "# Only select valid values and label other values as NaN\n",
    "wb_income_share_20_per['Income Share'] = pd.to_numeric(income_share_20_per_values, errors='coerce')\n",
    "\n",
    "# Only select relevant columns\n",
    "wb_income_share_20_per = wb_income_share_20_per[['Country Name', 'Country Code', 'Income Share']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIM\n",
    "\n",
    "# We select the rightmost value (most recent) for each row\n",
    "wb_co2_values = wb_co2.stack().groupby(level=0).last().reindex(wb_co2.index)\n",
    "\n",
    "# Only select valid values and label other values as NaN\n",
    "wb_co2['CO2 Emissions'] = pd.to_numeric(wb_co2_values, errors='coerce')\n",
    "\n",
    "# Only keep most recent values for each country\n",
    "wb_co2 = wb_co2[['Country Name', 'Country Code', 'CO2 Emissions']]\n",
    "\n",
    "# Remove countries without indicator information\n",
    "wb_co2 = wb_co2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join UN datasets with country codes DataFrame\n",
    "un_hdi_components_2014 = un_hdi_components_2014.join(df_country_codes, on='Country')\n",
    "un_gdp_per_capita = un_gdp_per_capita.join(df_country_codes, on='Country')\n",
    "un_gdp_per_capita_ppp = un_gdp_per_capita_ppp.join(df_country_codes, on='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of UN DataFrames\n",
    "un_dfs = [un_hdi_components_2014, un_gdp_per_capita, un_gdp_per_capita_ppp]\n",
    "\n",
    "# Define dictionary containing pairs (country name: ISO country code)\n",
    "countries = dict()\n",
    "\n",
    "for country in pycountry.countries:\n",
    "    countries[country.name] = country.alpha_3  \n",
    "\n",
    "for df in un_dfs:\n",
    "    nan_values = df['CODE'].isna()\n",
    "    input_countries = list(df[nan_values]['Country'].values)\n",
    "        \n",
    "    codes = []\n",
    "    for country in input_countries:\n",
    "        if country in countries:\n",
    "            codes.append(countries.get(country))\n",
    "        else:        \n",
    "            accepted = []\n",
    "            str_country = str(country)\n",
    "            # check if string contains either common or official country name\n",
    "            for p_country in pycountry.countries:\n",
    "                if p_country.name in str_country or (hasattr(p_country, 'common_name') and p_country.common_name in str_country):\n",
    "                    accepted.append(p_country.alpha_3)\n",
    "            if len(accepted) == 1:\n",
    "                codes.append(accepted[0])\n",
    "            else:\n",
    "                codes.append(None)\n",
    "\n",
    "    df.loc[nan_values, 'CODE'] = codes\n",
    "    # Remove rows that were not found\n",
    "    df = df[df['CODE'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp_references_country = pp_nodes_address.groupby(['country_codes', 'countries']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_population_2014 = wb_population_total[['Country Code', '2014']]\n",
    "occurrence_pop = pp_references_country.merge(wb_population_2014, left_on='country_codes', right_on='Country Code')\n",
    "occurrence_pop['counts_1000'] = 1000 * occurrence_pop['counts'] / occurrence_pop['2014']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis and observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Panama Papers and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_intermediary_country = pp_nodes_intermediary.groupby(['country_codes', 'countries']).size().reset_index(name='counts')\n",
    "pp_intermediary_country = pp_intermediary_country.sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the distribution using a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ dict(\n",
    "        type = 'choropleth',\n",
    "        locations = pp_intermediary_country['country_codes'],\n",
    "        z = pp_intermediary_country['counts'],\n",
    "        text = pp_intermediary_country['countries'],\n",
    "        colorscale = [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n",
    "            [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]],\n",
    "        autocolorscale = False,\n",
    "        reversescale = True,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(180,180,180)',\n",
    "                width = 0.5\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            autotick = False,\n",
    "            tickprefix = '',\n",
    "            title = 'Number of references'),\n",
    "      ) ]\n",
    "\n",
    "\"\"\"\n",
    "layout = {\n",
    "  \"geo\": {\n",
    "    \"coastlinewidth\": 2, \n",
    "    \"countrycolor\": \"rgb(204, 204, 204)\", \n",
    "    \"lakecolor\": \"rgb(255, 255, 255)\", \n",
    "    \"landcolor\": \"rgb(204, 204, 204)\", \n",
    "    \"lataxis\": {\n",
    "      \"dtick\": 10, \n",
    "      \"range\": [20, 60], \n",
    "      \"showgrid\": True\n",
    "    }, \n",
    "    \"lonaxis\": {\n",
    "      \"dtick\": 20, \n",
    "      \"range\": [-100, 20], \n",
    "      \"showgrid\": True\n",
    "    }, \n",
    "    \"projection\": {\"type\": \"equirectangular\"}, \n",
    "    \"resolution\": 50, \n",
    "    \"showlakes\": True, \n",
    "    \"showland\": False\n",
    "  }, \n",
    "  \"showlegend\": False, \n",
    "  \"title\": \"Seoul to Hong Kong Great Circle\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "layout = dict(\n",
    "    title = 'References in Panama Papers',\n",
    "    geo = dict(\n",
    "        showcountries = True,\n",
    "        countrycolor = \"rgb(217, 217, 217)\",\n",
    "        showframe = False,\n",
    "        resolution=50,\n",
    "        showcoastlines = False,\n",
    "        projection = dict(\n",
    "            type = 'Mercator'\n",
    "        ),\n",
    "        bgcolor = 'rgba(255, 255, 255, 0.0)',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "\n",
    "iplot( fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = pp_intermediary_country['counts'].min()\n",
    "max_count = pp_intermediary_country['counts'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstOrDefault(values, default):\n",
    "    if values is None or len(values) == 0:\n",
    "        return default\n",
    "    return values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the tables that most of the countries involved in the Panama Papers affair are small islands, which unfortunately are not displayed by the `Plotly` library. For the next milestone, we will fix that issue either by finding a solution that still works with `Plotly` or by using a different library, such as `folium`.\n",
    "\n",
    "So far, we have made insightful observations that match the reports found in the media, particularly about which countries were most involved in this affair.\n",
    "\n",
    "For the next milestone, we will further investigate the links between the countries, and try to understand the correlation of socio-economic factors with the locations of entities, officers and intermediaries involved in Panama Papers. More specifically, we intend to:\n",
    "- Find which socio-economic factors are correlated with the results we found so far, and how they are correlated\n",
    "- Display the links between the countries using a graph similar to the one found [here](https://plot.ly/python/lines-on-maps/)\n",
    "- Fix issues with certain countries (particularly small islands) not being displayed in the graph\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep columns relevant for plotting data\n",
    "nodes_intermediary_parsed = pp_nodes_intermediary[['node_id', 'country_codes', 'countries']]\n",
    "nodes_entity_parsed = pp_nodes_entity[['node_id', 'country_codes', 'countries']]\n",
    "nodes_officer_parsed = pp_nodes_officer[['node_id', 'country_codes', 'countries']]\n",
    "nodes_address_parsed = pp_nodes_address[['node_id', 'country_codes', 'countries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National and international links: geographical representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be displaying the different nodes on a world map, we need the latitude and longitude of each country. We use the following [dataset](https://opendata.socrata.com/dataset/Country-List-ISO-3166-Codes-Latitude-Longitude/mnkm-8ram) provided by Socrata to get the average latitude and longitude of every country. We store the dataset as a DataFrame and clean it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_location = pd.read_csv('data/countries_latitude_longitude.csv')\n",
    "countries_location = countries_location[['Alpha-3 code', 'Latitude (average)', 'Longitude (average)']]\n",
    "countries_location = countries_location.rename(columns={'Alpha-3 code': 'Code', 'Latitude (average)': 'lat', \n",
    "                                                        'Longitude (average)': 'long'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the nodes in Panama Papers that have a country attached to them, so that we can see how different people and firms and companies interact on an international level. We create a DataFrame `nodes` to represent the node ID and country representing that node, as well as the country's central coordinates that we previously obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame containing (id, country code, country name) for every node in Panama Papers\n",
    "nodes = nodes_entity_parsed.append(nodes_intermediary_parsed).append(nodes_officer_parsed).append(nodes_address_parsed)\n",
    "\n",
    "# certain nodes are irrepresentative, without a country code and name, so we drop them\n",
    "nodes = nodes.dropna()\n",
    "\n",
    "# set latitude and longitude for every node\n",
    "nodes = nodes.merge(countries_location, left_on='country_codes', right_on='Code').drop(columns='Code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a DataFrame containing the geographical location of origin and destination of each edge in Panama Papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get country of origin nodes\n",
    "edges_countries = nodes.merge(pp_edges[['START_ID', 'TYPE', 'END_ID']], left_on='node_id', right_on='START_ID')\n",
    "edges_countries = edges_countries.rename(columns={'node_id': 'id_1', 'country_codes': 'cc_1', \n",
    "                                                        'countries': 'country_1', 'lat': 'lat_1', 'long': 'long_1'})\n",
    "\n",
    "# get country of destination nodes\n",
    "edges_countries = edges_countries.merge(nodes, left_on='END_ID', right_on='node_id')\n",
    "edges_countries = edges_countries.rename(columns={'node_id': 'id_2', 'country_codes': 'cc_2', \n",
    "                                                        'countries': 'country_2', 'lat': 'lat_2', 'long': 'long_2'})\n",
    "\n",
    "# only keep relevant columns\n",
    "edges_countries = edges_countries.drop(columns=['id_1', 'id_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now separate the DataFrame containing edges into two DataFrames, one containing edges that are within a country and one containing edges that are international:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask to get edges that are within a country\n",
    "within_country = edges_countries['cc_1'] == edges_countries['cc_2']\n",
    "\n",
    "# remove countries that do not have international connections\n",
    "edges_international = edges_countries[~within_country]\n",
    "edges_national = edges_countries[within_country]\n",
    "\n",
    "print(\"Number of international edges %d\" % len(edges_international))\n",
    "print(\"Number of national edges: %d\" % len(edges_national))\n",
    "print(\"Ratio of international to national edges: %.2f\" % (len(edges_international)/len(edges_national)))\n",
    "\n",
    "# get total number of national edges by country\n",
    "edges_national = edges_national.groupby(['cc_1', 'country_1', 'TYPE']).size().reset_index(name='count')\n",
    "\n",
    "# get total number of international edges by each pair of countries\n",
    "# reset index twice for future data manipulation\n",
    "edges_international = edges_international.groupby(['cc_1', 'country_1', 'cc_2', 'country_2', \n",
    "                                'long_1', 'lat_1', 'long_2', 'lat_2', 'TYPE']).size().reset_index(name='count')\\\n",
    "                                .sort_values('count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the majority of edges are national, with approximately twice as many national edges when compared to international ones.\n",
    "\n",
    "### National links\n",
    "\n",
    "We display a world map showing the distribution of national links in the Panama Papers in different countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [ dict(\n",
    "        type = 'choropleth',\n",
    "        locations = edges_national['cc_1'],\n",
    "        z = edges_national['count'],\n",
    "        text = edges_national['country_1'],\n",
    "        colorscale = [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n",
    "            [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]],\n",
    "        autocolorscale = False,\n",
    "        reversescale = True,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(180,180,180)',\n",
    "                width = 0.5\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            autotick = False,\n",
    "            tickprefix = '',\n",
    "            title = 'Number of references'),\n",
    "      ) ]\n",
    "\n",
    "layout = dict(\n",
    "    title = 'Distribution of national Panama Papers links',\n",
    "    geo = dict(\n",
    "        showcountries = True,\n",
    "        countrycolor = \"rgb(217, 217, 217)\",\n",
    "        showframe = False,\n",
    "        resolution=10,\n",
    "        showcoastlines = False,\n",
    "        projection = dict(type = 'Mercator'),\n",
    "        bgcolor = 'rgba(255, 255, 255, 0.0)',\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "plot(fig, filename='../TrovatelliT.github.io/ressources/national_links_map.html', auto_open=False, validate=False)\n",
    "iplot(fig, filename='national_links_map', validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the world map that Switzerland has almost one sixth of all the national links, and that China has an additional eighth of the links. This is unsurprising, as Switzerland's economy is strongly focused on banks, and China has the world's largest population for a country.\n",
    "\n",
    "### International links\n",
    "\n",
    "We will now consider international links in Panama Papers. We will be representing these links as an undirected graph, so we must add links that have origin country A and destination country B and add them to links that have origin country B and destination country A. The nodes of our graph are the countries involved in Panama Papers, and we store these nodes in `nodes_countries`. We construct the international links graph in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes are countries, so former node_id values are irrelevant\n",
    "nodes_countries = nodes.drop(columns='node_id').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we reverse the direction of the edges\n",
    "edges_international_rev = edges_international.rename(columns={'cc_1': 'cc_2', 'cc_2': 'cc_1',\n",
    "                                'country_1': 'country_2', 'country_2': 'country_1',\n",
    "                                'long_1': 'long_2', 'long_2': 'long_1',\n",
    "                                'lat_1': 'lat_2', 'lat_2': 'lat_1'})\n",
    "\n",
    "# add edges in original direction with those in reverse direction\n",
    "edges_international_total = edges_international.append(edges_international_rev, sort=True).groupby(['cc_1', 'cc_2', \n",
    "                                    'country_1', 'country_2', 'lat_1', 'lat_2', 'long_1', 'long_2']).sum().reset_index()\n",
    "\n",
    "# filter edges by lexographic order, to remove any duplicate edges\n",
    "edges_international_total = edges_international_total[edges_international_total.apply(\n",
    "                                lambda r: r['cc_1'] < r['cc_2'] , axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [ dict(\n",
    "        type = 'scattergeo',\n",
    "        lon = nodes_countries['long'],\n",
    "        lat = nodes_countries['lat'],\n",
    "        hoverinfo = 'text',\n",
    "        text = nodes_countries['countries'],\n",
    "        mode = 'markers',\n",
    "        marker = dict( \n",
    "            size=3, \n",
    "            color='rgb(0, 0, 0)',\n",
    "            line = dict(\n",
    "                width=3,\n",
    "                color='rgba(68, 68, 68, 0)'\n",
    "            )\n",
    "        ))]\n",
    "\n",
    "edges = []\n",
    "for i in range(len(edges_international_total)):    \n",
    "    edges.append(\n",
    "        dict(type = 'scattergeo',\n",
    "            lon = [edges_international_total['long_1'].iloc[i], edges_international_total['long_2'].iloc[i]],\n",
    "            lat = [edges_international_total['lat_1'].iloc[i], edges_international_total['lat_2'].iloc[i]],\n",
    "            mode = 'lines',\n",
    "            hoverinfo = 'none',\n",
    "            line = dict(\n",
    "                width =  max(edges_international_total['count'].iloc[i]/2000, .02),\n",
    "                color = 'red'\n",
    "            ))\n",
    "    )\n",
    "    \n",
    "layout = dict(\n",
    "        title = 'International Panama Papers links',\n",
    "        showlegend = False, \n",
    "        geo2 = dict(\n",
    "        showcountries = True,\n",
    "        countrycolor = \"rgb(217, 217, 217)\",\n",
    "        showframe = False,\n",
    "        resolution = 10,\n",
    "        showcoastlines = False,\n",
    "        projection = dict(type = 'Mercator'),\n",
    "        bgcolor = 'rgba(255, 255, 255, 0.0)'\n",
    "    ))\n",
    "    \n",
    "fig = dict(data=edges + countries, layout=layout)\n",
    "plot(fig, filename='../TrovatelliT.github.io/ressources/international_links_map.html', auto_open=False, validate=False)\n",
    "iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the geographic representation of the distribution of Panama Papers links above, we notice that the majority of links are transatlantic. Specifically, most of the large links are between Central America and Central Europe. However, the largest link is between China and Hong Kong. This is logical, because there are over 20000 links originating from China to Hong Kong, which is by far the largest number of connections between any two countries (the next largest one is approximately 5000). We will investigate what the majority of these links are below.\n",
    "\n",
    "We can also see some other \"link hubs\" that we expected to see, like the UAE, the Bahamas and Singapore. The UAE and Singapore are both big business centers with many international links, and the Bahamas is one of the many visible fiscal paradises on the map, because there is no tax on personal income or capital gains for citizens and residents.\n",
    "\n",
    "We want to find out what the majority of the links between China and Hong Kong represent. We do so below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges representing officer links\n",
    "edges_officer = edges_international[edges_international['TYPE'] == 'officer_of']\n",
    "\n",
    "# edges representing intermediary links\n",
    "edges_intermediary = edges_international[edges_international['TYPE'] == 'intermediary_of']\n",
    "\n",
    "# edges representing address links\n",
    "edges_address = edges_international[edges_international['TYPE'] == 'registered_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top edges representing officers based in China\n",
    "edges_officer.loc[edges_officer['country_1'] == 'China'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the majority of links between China and Hong Kong is due to a large number of officers, which are shareholders and beneficiaries based in China that work with companies that are based in Hong Kong. This makes sense, as Hong Kong is considered a tax haven, and it is the closest tax haven there is to China in terms of geography and culture, which makes it preferable for Chinese businessmen to work with Hong Kongese companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International links: network representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_file, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges, EdgesAndLinkedNodes\n",
    "from bokeh.models import Plot, Range1d, MultiLine, Circle, HoverTool, TapTool, BoxSelectTool, BoxZoomTool,\\\n",
    "        ResetTool, LassoSelectTool, WheelZoomTool, PanTool\n",
    "from bokeh.palettes import Spectral4, Inferno, Viridis\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import file_html\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to see which countries are the most important in the Panama Papers affair, in terms of their centrality. To do so, we will be using a network representation of the links between countries related to Panama Papers. We construct a graph with countries involved being the nodes, and the edges being links between the countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_network = pd.DataFrame(edges_international_total.groupby('country_1').size()).reset_index().rename(columns={0: 'degree'})\n",
    "# nodes_network['country'] = nodes_network['country_1'] # in case degree is used\n",
    "# edges_network = edges_network.merge(nodes_network[['country_1', 'degree']]) # in case degree is used\n",
    "\n",
    "# dictionary containing names of nodes in network that are edge origins\n",
    "nodes_names_dict = pd.DataFrame(edges_international_total['country_1']).rename(columns={'country_1': 'country'})\\\n",
    "                        .set_index('country', drop=False).to_dict()['country']\n",
    "\n",
    "# add nodes that are only destinations in network, and never origins\n",
    "additional_nodes = list(set(edges_international_total['country_2']).difference(\n",
    "                        set(edges_international_total['country_1'])))\n",
    "additional_nodes_names_dict = {node: node for node in additional_nodes}\n",
    "\n",
    "# add destination nodes to origin nodes dictionary\n",
    "nodes_names_dict.update(additional_nodes_names_dict)\n",
    "\n",
    "# DF containing each edge in the network\n",
    "edges_network = edges_international_total[['country_1', 'country_2', 'count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display the network with edges with varying opacity, representing the number of links between the two countries. The node size will reflect the betweenness centrality of the node. Betweenness centrality is a quantification of the number of times that a node acts as a bridge in the shortest path between any two other nodes. This will allow us to see who the important actors are in the Panama Papers affair. We add these edge and node attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(edges_network, source='country_1', target='country_2')\n",
    "\n",
    "G.add_nodes_from(additional_nodes)\n",
    "\n",
    "# set edge opacity attribute\n",
    "edge_attrs = {}\n",
    "for origin, dest in G.edges():\n",
    "    query = edges_network.loc[(edges_network['country_1'] == origin)].loc[(edges_network['country_2'] == dest)]\n",
    "    if len(query) > 0:\n",
    "        count = query.iloc[0]['count']\n",
    "        edge_attrs[(origin, dest)] = min(max(count / 2000, 0.2), 1)\n",
    "        \n",
    "# set node size attribute\n",
    "nodes_centrality_dict = nx.betweenness_centrality(G)\n",
    "for k, v in nodes_centrality_dict.items():\n",
    "    nodes_centrality_dict[k] = np.clip(int(v*200), a_min=3, a_max=40)\n",
    "    \n",
    "# set node and edge attributes\n",
    "nx.set_node_attributes(G, nodes_names_dict, name='country')\n",
    "nx.set_node_attributes(G, nodes_centrality_dict, name='centrality')\n",
    "nx.set_edge_attributes(G, edge_attrs, name='edge_opacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_centrality_dict['Panama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot = Plot(plot_width=600, plot_height=600, x_range=Range1d(-1.1,1.1), y_range=Range1d(-1.1,1.1))\n",
    "plot.title.text = \"Panama Papers connections\"\n",
    "\n",
    "node_hover_tool = HoverTool(tooltips=[(\"Country\", \"@country\")])\n",
    "\n",
    "plot.add_tools(node_hover_tool, TapTool(), BoxSelectTool(), BoxZoomTool(), ResetTool(), \n",
    "               LassoSelectTool(), WheelZoomTool(), PanTool())\n",
    "\n",
    "graph_renderer = from_networkx(G, nx.spring_layout, scale=1, center=(0,0))\n",
    "\n",
    "graph_renderer.node_renderer.glyph = Circle(size=\"centrality\", fill_color=Inferno[4][2], line_color=\"#000000\")\n",
    "graph_renderer.node_renderer.selection_glyph = Circle(size=12, fill_color=Inferno[6][4])\n",
    "graph_renderer.node_renderer.hover_glyph = Circle(size=12, fill_color=Inferno[5][3])\n",
    "\n",
    "graph_renderer.edge_renderer.glyph = MultiLine(line_color=Inferno[5][1], line_alpha=\"edge_opacity\", line_width=2)\n",
    "graph_renderer.edge_renderer.selection_glyph = MultiLine(line_color=Inferno[6][2], line_width=3)\n",
    "graph_renderer.edge_renderer.hover_glyph = MultiLine(line_color=Inferno[7][3], line_width=2)\n",
    "\n",
    "# for colors https://bokeh.pydata.org/en/latest/docs/reference/palettes.html\n",
    "\n",
    "graph_renderer.selection_policy = NodesAndLinkedEdges()\n",
    "graph_renderer.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "plot.renderers.append(graph_renderer)\n",
    "\n",
    "output_file('../TrovatelliT.github.io/ressources/international_links_network.html')\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the network representation we can clearly see the major actors in the Panama Papers. The biggest nodes by far are Hong Kong and Switzerland. This isn't surprising. The majority of links connecting to Hong Kong are with China and Panama, which are both international link hubs, as we saw from the geographical distribution of international links. Switzerland is also a financial hub, justifying its centrality.\n",
    "\n",
    "Interestingly, the other major nodes aren't only fiscal paradises, as one would expect. Both the UAE and Russia are central nodes, meaning that they have more international links than most countries. China has a relatively low betwenness centrality, which is explained by the fact that most of the links related to China go simply to Hong Kong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case study: Queen of England"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.asiaone.com/world/what-are-panama-papers-and-who-have-been-implicated\n",
    "\n",
    "pp_nodes_officer = pp_nodes_officer.dropna(subset=['name'])\n",
    "pp_nodes_entity = pp_nodes_entity.dropna(subset=['name'])\n",
    "\n",
    "# daughter of former chinese premier: li xiaolin\n",
    "li_xiaolin = pp_nodes_entity[pp_nodes_entity['name'].str.contains('COFIC INVESTMENTS LTD.')]\n",
    "\n",
    "# president of argentina: mauricio macri\n",
    "mauricio_macri = pp_nodes_entity[pp_nodes_entity['name'].str.contains('FLEG TRADING LTD')]\n",
    "\n",
    "# football player: lionel messi\n",
    "lionel_messi = pp_nodes_entity[pp_nodes_entity['name'].str.contains('MEGA STAR ENTERPRISES')]\n",
    "\n",
    "# uae abu dhabi emir: khalifa bin zayed\n",
    "khalifa_bin_zayed = pp_nodes_officer[pp_nodes_officer['name'].str.contains('KHALIFA BIN ZAYED')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
